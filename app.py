import streamlit as st
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
from deep_translator import GoogleTranslator
import io
import re

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ç”»åƒãƒªãƒãƒ¼ãƒ ãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ·ï¸ ç”»åƒãƒªãƒãƒ¼ãƒ ãƒ„ãƒ¼ãƒ« (ç·¨é›†ãƒ»å€‹åˆ¥DLæ©Ÿèƒ½ä»˜)")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– ---
# è§£æçµæœã‚’ä¿æŒã™ã‚‹ãŸã‚ã«å¿…è¦
if 'processed_images' not in st.session_state:
    st.session_state.processed_images = []

# --- AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ ---
@st.cache_resource
def load_model():
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base")
    return processor, model

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: è‹±èªã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰è¦ç´ ã‚’æŠ½å‡º ---
def analyze_caption(caption_en, selected_genre):
    caption_lower = caption_en.lower()
    
    # 1. æ€§åˆ¥ (Gender)
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    gender = "äººç‰©"
    
    # å®¶æ—ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—åˆ¤å®š (å„ªå…ˆåº¦é«˜)
    if any(w in caption_lower for w in ['family', 'group', 'crowd', 'children', 'kids', 'people']):
        gender = "å®¶æ—"
    # ç”·å¥³æ··åˆ
    elif ('man' in caption_lower or 'boy' in caption_lower) and ('woman' in caption_lower or 'girl' in caption_lower):
        gender = "ç”·å¥³"
    # å¥³æ€§
    elif any(w in caption_lower for w in ['woman', 'girl', 'lady', 'female']):
        gender = "å¥³æ€§"
    # ç”·æ€§
    elif any(w in caption_lower for w in ['man', 'boy', 'guy', 'male']):
        gender = "ç”·æ€§"

    # 2. äººæ•° (Count)
    count = "1äºº" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    # æ•°å­—å˜èªã®è¾æ›¸
    num_dict = {
        'one': '1äºº', 'a ': '1äºº', 'an ': '1äºº',
        'two': '2äºº', 'couple': '2äºº', 'pair': '2äºº',
        'three': '3äºº', 'four': '4äºº', 'five': '5äºº',
        'six': '6äºº', 'seven': '7äºº', 'eight': '8äºº', 'nine': '9äºº', 'ten': '10äºº'
    }
    
    # ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‹ã‚‰æ•°å­—ã‚’æ¢ã™
    found_count = False
    tokens = caption_lower.split()
    for token in tokens:
        if token in num_dict:
            count = num_dict[token]
            found_count = True
            break
    
    # å˜èªãŒè¦‹ã¤ã‹ã‚‰ãšã€è¤‡æ•°å½¢ã®å…†å€™ãŒã‚ã‚‹å ´åˆ
    if not found_count:
        if gender == "å®¶æ—" or gender == "ç”·å¥³":
            count = "è¤‡æ•°"
        elif "people" in caption_lower:
            count = "è¤‡æ•°"

    # 3. å‹•ä½œ (Action) - ç¿»è¨³
    try:
        action_jp = GoogleTranslator(source='en', target='ja').translate(caption_en)
        action_jp = re.sub(r'[\\/:*?"<>|]', '', action_jp) # ãƒ•ã‚¡ã‚¤ãƒ«åç¦æ­¢æ–‡å­—å‰Šé™¤
        action_jp = action_jp.replace(" ", "_")
        if len(action_jp) > 15: # é•·ã™ãã‚‹å ´åˆã¯ã‚«ãƒƒãƒˆ
            action_jp = action_jp[:15]
    except:
        action_jp = "å‹•ä½œ"

    # çµåˆã—ã¦è¿”ã™ (ã‚¸ãƒ£ãƒ³ãƒ«_æ€§åˆ¥_äººæ•°_å‹•ä½œ)
    return f"{selected_genre}_{gender}_{count}_{action_jp}"

# --- ãƒ¡ã‚¤ãƒ³UI ---

# ã‚µã‚¤ãƒ‰ãƒãƒ¼: è¨­å®šãªã©
with st.sidebar:
    st.header("è¨­å®š")
    # ã‚¸ãƒ£ãƒ³ãƒ«é¸æŠ (ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®š)
    selected_genre = st.selectbox(
        "ã‚¸ãƒ£ãƒ³ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ãƒ€ã‚¤ã‚¨ãƒƒãƒˆ", "è‚²æ¯›", "ç¾å®¹", "ãƒ“ã‚¸ãƒã‚¹", "ä»‹è­·", "ãã®ä»–"],
        index=0
    )

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.write("##### 1. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
uploaded_files = st.file_uploader(
    "ãƒªãƒãƒ¼ãƒ ã—ãŸã„ç”»åƒã‚’é¸æŠ (è¤‡æ•°å¯)", 
    type=["jpg", "jpeg", "png"], 
    accept_multiple_files=True
)

# è§£æãƒœã‚¿ãƒ³
if uploaded_files:
    if st.button("ç”»åƒã‚’è§£æã—ã¦åå‰ã‚’ä»˜ã‘ã‚‹", type="primary"):
        st.session_state.processed_images = [] # ãƒªã‚»ãƒƒãƒˆ
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
        with st.spinner('AIãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ä¸­...'):
            processor, model = load_model()

        # è§£æãƒ«ãƒ¼ãƒ—
        progress_bar = st.progress(0)
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                # ç”»åƒèª­ã¿è¾¼ã¿
                image = Image.open(uploaded_file).convert('RGB')
                
                # AIè§£æ
                inputs = processor(image, return_tensors="pt")
                out = model.generate(**inputs, max_new_tokens=50)
                caption_en = processor.decode(out[0], skip_special_tokens=True)
                
                # å‘½åç”Ÿæˆ
                base_name = analyze_caption(caption_en, selected_genre)
                
                # æ‹¡å¼µå­å‡¦ç†
                original_ext = uploaded_file.name.split('.')[-1].lower()
                if original_ext == 'jpeg': original_ext = 'jpg'
                
                # ä¿å­˜å½¢å¼ã®åˆ¤å®š
                save_format = 'PNG' if original_ext == 'png' else 'JPEG'
                mime_type = "image/png" if original_ext == 'png' else "image/jpeg"

                # ãƒ‡ãƒ¼ã‚¿ä¿æŒ
                st.session_state.processed_images.append({
                    "id": i,
                    "image": image,
                    "original_name": uploaded_file.name,
                    "default_base_name": base_name, # åˆæœŸå€¤
                    "ext": original_ext,
                    "save_format": save_format,
                    "mime_type": mime_type,
                    "caption_debug": caption_en
                })
                
            except Exception as e:
                st.error(f"{uploaded_file.name} ã®ã‚¨ãƒ©ãƒ¼: {e}")
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        st.success("è§£æå®Œäº†ï¼ä¸‹ã®ä¸€è¦§ã‹ã‚‰ç¢ºèªãƒ»ç·¨é›†ã—ã¦ãã ã•ã„ã€‚")

# --- çµæœè¡¨ç¤ºã¨ç·¨é›†ã‚¨ãƒªã‚¢ ---
if st.session_state.processed_images:
    st.write("---")
    st.write("##### 2. ç¢ºèªãƒ»ç·¨é›†ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    st.info("ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å¤‰æ›´ã—ã¦ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€å¤‰æ›´å¾Œã®åå‰ã§ä¿å­˜ã•ã‚Œã¾ã™ã€‚")

    # ã‚°ãƒªãƒƒãƒ‰è¡¨ç¤ºã£ã½ãè¦‹ã›ã‚‹ãŸã‚ã®ã‚¹ã‚¿ã‚¤ãƒ«èª¿æ•´
    for item in st.session_state.processed_images:
        with st.container():
            col1, col2, col3 = st.columns([1, 2, 1])
            
            # å·¦ã‚«ãƒ©ãƒ : ã‚µãƒ ãƒã‚¤ãƒ«
            with col1:
                st.image(item['image'], width=150)
                st.caption(f"å…ƒ: {item['original_name']}")
            
            # ä¸­å¤®ã‚«ãƒ©ãƒ : å‘½åç·¨é›† (æ‹¡å¼µå­ãªã—)
            with col2:
                # keyã«IDã‚’å«ã‚ã‚‹ã“ã¨ã§ã€å„ç”»åƒã®å…¥åŠ›æ¬„ã‚’è­˜åˆ¥ã™ã‚‹
                new_base_name = st.text_input(
                    "ãƒ•ã‚¡ã‚¤ãƒ«å (æ‹¡å¼µå­ãªã—)",
                    value=item['default_base_name'],
                    key=f"input_{item['id']}"
                )
                st.caption(f"AIèªè­˜: {item['caption_debug']}")

            # å³ã‚«ãƒ©ãƒ : ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            with col3:
                # æœ€çµ‚çš„ãªãƒ•ã‚¡ã‚¤ãƒ«åã‚’çµåˆ
                final_filename = f"{new_base_name}.{item['ext']}"
                
                # ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚¤ãƒˆåˆ—ã«å¤‰æ›
                img_byte_arr = io.BytesIO()
                item['image'].save(img_byte_arr, format=item['save_format'])
                img_data = img_byte_arr.getvalue()
                
                st.write("") # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ç”¨ã®ç©ºç™½
                st.write("") 
                st.download_button(
                    label="â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=img_data,
                    file_name=final_filename,
                    mime=item['mime_type'],
                    key=f"btn_{item['id']}"
                )
            st.divider() # åŒºåˆ‡ã‚Šç·š
