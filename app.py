import streamlit as st
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration
from deep_translator import GoogleTranslator
import io
import re

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="é«˜ç²¾åº¦ç”»åƒãƒªãƒãƒ¼ãƒ ãƒ„ãƒ¼ãƒ«", layout="wide")
st.title("ğŸ·ï¸ ç”»åƒãƒªãƒãƒ¼ãƒ ãƒ„ãƒ¼ãƒ« Pro (é«˜ç²¾åº¦ç‰ˆ)")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ ---
if 'processed_images' not in st.session_state:
    st.session_state.processed_images = []

# --- AIãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ (Largeãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›´) ---
@st.cache_resource
def load_model():
    # 'base' ã‹ã‚‰ 'large' ã«å¤‰æ›´ã—ã¦ç²¾åº¦å‘ä¸Š
    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-large")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-large")
    return processor, model

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã®ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° ---
def clean_caption_text(text):
    """ç¿»è¨³å‰ã«è‹±èªã®ãƒã‚¤ã‚ºã‚’é™¤å»ã—ã¦è‡ªç„¶ãªè¡¨ç¾ã«ã—ã‚„ã™ãã™ã‚‹"""
    text = text.lower()
    # BLIPãƒ¢ãƒ‡ãƒ«ç‰¹æœ‰ã®ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆè¬å˜èªï¼‰ã‚„ä¸è¦ãªå®šå‹å¥ã‚’å‰Šé™¤
    remove_words = [
        "arafed", "view of", "close up of", "picture of", "image of", 
        "looking at the camera", "with a white background", "in the background"
    ]
    for w in remove_words:
        text = text.replace(w, "")
    return text.strip()

# --- ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: è§£æãƒ­ã‚¸ãƒƒã‚¯ ---
def analyze_caption(caption_en, selected_genre):
    # 1. ã¾ãšè‹±èªã‚’ãã‚Œã„ã«ã™ã‚‹
    clean_en = clean_caption_text(caption_en)
    
    # --- æ€§åˆ¥ (Gender) ---
    gender = "äººç‰©"
    if any(w in clean_en for w in ['family', 'group', 'crowd', 'children', 'kids', 'people', 'friends']):
        gender = "å®¶æ—"
    elif ('man' in clean_en or 'boy' in clean_en) and ('woman' in clean_en or 'girl' in clean_en):
        gender = "ç”·å¥³"
    elif any(w in clean_en for w in ['woman', 'girl', 'lady', 'female', 'bride']):
        gender = "å¥³æ€§"
    elif any(w in clean_en for w in ['man', 'boy', 'guy', 'male']):
        gender = "ç”·æ€§"

    # --- äººæ•° (Count) ---
    count = "1äºº"
    num_dict = {
        'one': '1äºº', 'two': '2äºº', 'three': '3äºº', 'four': '4äºº', 'five': '5äºº',
        'couple': '2äºº', 'pair': '2äºº', 'group': 'è¤‡æ•°', 'crowd': 'è¤‡æ•°'
    }
    # å˜èªãƒãƒƒãƒãƒ³ã‚°
    for word, jp_count in num_dict.items():
        if f" {word} " in f" {clean_en} ": # å‰å¾Œã«ã‚¹ãƒšãƒ¼ã‚¹ã‚’å…¥ã‚Œã¦å˜èªã¨ã—ã¦åˆ¤å®š
            count = jp_count
            break
            
    # --- å‹•ä½œ (Action) - ç¿»è¨³ã®æ”¹å–„ ---
    try:
        # æ–‡å…¨ä½“ã§ã¯ãªãã€å‹•è©å¥ã‚„é‡è¦ãªéƒ¨åˆ†ã‚’ä¸­å¿ƒã«ç¿»è¨³ã•ã›ã‚‹å·¥å¤«
        # Googleç¿»è¨³ã«ã‹ã‘ã‚‹
        action_jp = GoogleTranslator(source='en', target='ja').translate(clean_en)
        
        # è¨˜å·å‰Šé™¤
        action_jp = re.sub(r'[\\/:*?"<>|]', '', action_jp)
        action_jp = action_jp.replace(" ", "_").replace("ã€€", "_")
        
        # ã€Œã€œã®ã€ã§çµ‚ã‚ã‚‹ã‚ˆã†ãªå¤‰ãªç¿»è¨³ã‚’ã‚«ãƒƒãƒˆ (ä¾‹: æ¤…å­ã®ä¸Šã® -> æ¤…å­ã®ä¸Š)
        if action_jp.endswith("ã®"):
            action_jp = action_jp[:-1]
            
        # é•·ã™ãã‚‹ä¿®é£¾èªã‚’ã‚«ãƒƒãƒˆã™ã‚‹ãŸã‚ã®ç°¡æ˜“å‡¦ç†
        # (æ—¥æœ¬èªã®åŠ©è©ã€Œã§ã€ã€Œã«ã€ã€Œã‚’ã€ã§åŒºåˆ‡ã£ã¦ã€æœ€å¾Œã®æ–¹ï¼ˆå‹•ä½œï¼‰ã ã‘æ®‹ã™ãªã©)
        if len(action_jp) > 20:
             action_jp = action_jp[:20]

    except:
        action_jp = "å‹•ä½œä¸æ˜"

    # çµåˆ (ã‚¸ãƒ£ãƒ³ãƒ«_æ€§åˆ¥_äººæ•°_å‹•ä½œ)
    return f"{selected_genre}_{gender}_{count}_{action_jp}"

# --- UI ---
with st.sidebar:
    st.header("è¨­å®š")
    selected_genre = st.selectbox(
        "ã‚¸ãƒ£ãƒ³ãƒ«ã‚’é¸æŠ",
        ["ãƒ€ã‚¤ã‚¨ãƒƒãƒˆ", "è‚²æ¯›", "ç¾å®¹", "ãƒ“ã‚¸ãƒã‚¹", "ä»‹è­·", "ãã®ä»–"],
        index=0
    )

st.write("##### 1. ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
st.info("â€»ç²¾åº¦å‘ä¸Šã®ãŸã‚ã€ŒLargeãƒ¢ãƒ‡ãƒ«ã€ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚è§£æã«å°‘ã—æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ã€‚")
uploaded_files = st.file_uploader(
    "ç”»åƒã‚’é¸æŠ", 
    type=["jpg", "jpeg", "png"], 
    accept_multiple_files=True
)

if uploaded_files:
    if st.button("é«˜ç²¾åº¦è§£æã‚¹ã‚¿ãƒ¼ãƒˆ", type="primary"):
        st.session_state.processed_images = []
        
        with st.spinner('é«˜ç²¾åº¦AIãƒ¢ãƒ‡ãƒ«ã‚’èµ·å‹•ä¸­...'):
            processor, model = load_model()

        progress_bar = st.progress(0)
        
        for i, uploaded_file in enumerate(uploaded_files):
            try:
                image = Image.open(uploaded_file).convert('RGB')
                
                # --- AIç”Ÿæˆè¨­å®šã®å¼·åŒ– (ã“ã“ãŒé‡è¦) ---
                inputs = processor(image, return_tensors="pt")
                
                # num_beams=3: 3ã¤ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è€ƒãˆã¦ä¸€ç•ªè‰¯ã„ã‚‚ã®ã‚’é¸ã¶
                # min_length=15: çŸ­ã™ãã‚‹ç­”ãˆã‚’é˜²ã
                out = model.generate(
                    **inputs, 
                    max_new_tokens=50, 
                    min_length=10, 
                    num_beams=3, 
                    repetition_penalty=1.2 # åŒã˜å˜èªã®ç¹°ã‚Šè¿”ã—é˜²æ­¢
                )
                caption_en = processor.decode(out[0], skip_special_tokens=True)
                
                # å‘½åç”Ÿæˆ
                base_name = analyze_caption(caption_en, selected_genre)
                
                # æ‹¡å¼µå­ãªã©
                original_ext = uploaded_file.name.split('.')[-1].lower()
                if original_ext == 'jpeg': original_ext = 'jpg'
                save_format = 'PNG' if original_ext == 'png' else 'JPEG'
                mime_type = "image/png" if original_ext == 'png' else "image/jpeg"

                st.session_state.processed_images.append({
                    "id": i,
                    "image": image,
                    "original_name": uploaded_file.name,
                    "default_base_name": base_name,
                    "ext": original_ext,
                    "save_format": save_format,
                    "mime_type": mime_type,
                    "caption_debug": caption_en
                })
                
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        st.success("è§£æå®Œäº†ï¼")

# --- çµæœè¡¨ç¤º ---
if st.session_state.processed_images:
    st.write("---")
    st.write("##### 2. ç¢ºèªãƒ»ç·¨é›†ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    
    for item in st.session_state.processed_images:
        with st.container():
            col1, col2, col3 = st.columns([1, 2, 1])
            with col1:
                st.image(item['image'], width=150)
            with col2:
                new_base_name = st.text_input(
                    "ãƒ•ã‚¡ã‚¤ãƒ«å", value=item['default_base_name'], key=f"in_{item['id']}"
                )
                # ãƒ‡ãƒãƒƒã‚°ç”¨ã«è‹±èªåŸæ–‡ã‚‚è–„ãè¡¨ç¤ºï¼ˆç¿»è¨³ãŒãŠã‹ã—ã„æ™‚ã®ç¢ºèªç”¨ï¼‰
                st.caption(f"AIåŸæ–‡: {item['caption_debug']}")
            with col3:
                final_name = f"{new_base_name}.{item['ext']}"
                img_byte_arr = io.BytesIO()
                item['image'].save(img_byte_arr, format=item['save_format'])
                st.write("")
                st.write("")
                st.download_button(
                    "â¬‡ï¸ ä¿å­˜",
                    data=img_byte_arr.getvalue(),
                    file_name=final_name,
                    mime=item['mime_type'],
                    key=f"dl_{item['id']}"
                )
            st.divider()
